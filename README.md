# جستجوگر محصولات فروشگاهی ایتا (Eitaa Product Crawler)

## مقدمه
هدف از این پروژه پیاده‌سازی یک پایپ‌لاین هوشمند برای یافتن کانال‌های فروشگاهی در پیام‌رسان ایتا، اعتبارسنجی آن‌ها، استخراج اطلاعات محصولات و ارسال داده‌های استخراج‌شده به یک صف پردازشی می‌باشد.
تمرکز این پروژه بر معماری سیستم، کار با APIها، مدیریت صف و طراحی مقیاس‌پذیر است. (در این مرحله پیاده‌سازی کامل یک سیستم تولیدی مد نظر نیست)

---

## معماری کلی سیستم
سیستم به‌صورت یک پایپ‌لاین چندمرحله‌ای طراحی شده است:

1. **یافتن کانال‌ها (Discovery)**
2. **اعتبارسنجی کانال‌های فروشگاهی (Validation)**
3. **خزش و استخراج داده محصولات (Crawling & Extraction)**
4. **ارسال داده‌ها به صف (Queuing)**

داده‌های استخراج‌شده مستقیماً در پایگاه داده ذخیره نمی‌شوند و به‌عنوان Job در صف قرار می‌گیرند تا توسط سرویس‌های دیگر پردازش شوند.

---

## مراحل پایپ‌لاین

### 1. کشف کانال‌ها
در این مرحله، با استفاده از مجموعه‌ای از کلمات کلیدی مرتبط با فروش محصولات، کانال‌های کاندید از طریق قابلیت جستجوی Global ایتا استخراج می‌شوند.

> در نسخه MVP، کلمات کلیدی به‌صورت ثابت (hardcoded) تعریف شده‌اند و تولید داینامیک کلیدواژه ها با استفاده از مدل‌های زبانی (LLMs) به‌عنوان گامهای بعدی توسعه سیستم در نظر گرفته شده است.

---

### 2. اعتبارسنجی کانال‌ها
از آن‌جایی که بسیاری از کانال‌ها ممکن است از هشتگ‌های فروش استفاده کنند ولی فروشگاه نباشند، محتوای اولیه کانال (Bio و چند پست آخر) بررسی می‌شود تا فروشگاهی بودن کانال تشخیص داده شود.

این اعتبارسنجی می‌تواند به‌صورت:
- rule-based
- یا با استفاده از یک مدل زبانی ساده

انجام شود.
> از آنجایی که تمرکز اصلی این سرویس در مرحله MVP روی پالایش و آماده سازی اطلاعات پست های کانالهای فروشگاهی (برای پردازش های بعدی) است، اعتبارسنجی از طریق مدل زبانی فقط در صورت اجازه دادن ددلاین در این مرحله انجام خواهد شد. در غیر اینصورت به عنوان اولویت در مرحله بعدی توسعه محسوب خواهد شد.

---

### 3. پالایش و استخراج داده
برای کانال‌های تأییدشده:
- پیام‌ها پالایش یا خزش (crawl) می‌شوند
- پست‌های مرتبط با محصول از سایر پیام‌ها تفکیک می‌گردند
- اطلاعات محصول شامل متن کامل و لینک تصاویر استخراج می‌شود (extraction)

---

### 4. مدیریت صف (Redis)
هر محصول استخراج‌شده به‌صورت یک Job مستقل در صف Redis قرار می‌گیرد.
این طراحی باعث جداسازی فرآیند استخراج از پردازش‌های بعدی می‌شود و مقیاس‌پذیری سیستم را افزایش می‌دهد.

---

## کار با APIها
این پروژه شامل تعامل با چند API خارجی است:
- API پلتفرم ایتا (جستجو، دریافت پیام‌ها، فایل‌ها)
- API مدل‌های زبانی (در صورت استفاده)
- API Redis برای مدیریت صف

این کلاینت‌ها به‌گونه‌ای طراحی شده‌اند که مدیریت خطا، timeout، retry و محدودسازی ساده نرخ ارسال درخواست‌ها (در سطح هر درخواست) را پوشش دهند تا پایداری سیستم حفظ شود.

---

## مدیریت Rate Limit و Multi-Session
پلتفرم ایتا محدودیت‌هایی روی تعداد و سرعت درخواست‌های هر اکانت اعمال می‌کند. در نسخه MVP از یک session استفاده شده است، اما معماری سیستم به‌گونه‌ای طراحی شده که در مراحل بعدی امکان استفاده از چندین session و توزیع بار crawl بین آن‌ها وجود داشته باشد تا از بلاک شدن اکانت‌ها جلوگیری شود و مقیاس‌پذیری سیستم افزایش یابد.


---

## تکنولوژی‌های استفاده‌شده
- Python
- Redis
- Docker & Docker Compose

---

## محدودیت‌ها و تصمیمات طراحی
- در این نسخه از پایگاه داده استفاده نشده است. (فعلا نیازی نبوده است)
- تمرکز بر ارائه یک MVP پایدار و قابل توسعه بوده است.
- برخی قابلیت‌ها به‌عنوان بهبودسازی در آینده در نظر گرفته شده‌اند:
  - تمایز و تفکیک پست های فروشگاهی از غیر آن توسط مدل های زبانی
  - تولید کلمات کلیدی برای یافتن و کشف کانالهای فروشگاهی ایتا به صورت داینامیک و با استفاده از AI
  - پیاده سازی استفاده از چندین session و توزیع بار بین آنها
  - استخراج ویژگی های محصول

---

## اجرای پروژه
راهنمای اجرای پروژه از طریق Docker Compose در ادامه مستند شده است.
