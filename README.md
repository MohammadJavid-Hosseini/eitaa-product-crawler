# جستجوگر محصولات فروشگاهی ایتا (Eitaa Product Crawler)

## مقدمه
هدف از این پروژه پیاده‌سازی یک پایپ‌لاین هوشمند برای یافتن کانال‌های فروشگاهی در پیام‌رسان ایتا، اعتبارسنجی آن‌ها، استخراج اطلاعات محصولات و ارسال داده‌های استخراج‌شده به یک صف پردازشی می‌باشد.
تمرکز این پروژه بر معماری سیستم، کار با APIها، مدیریت صف و طراحی مقیاس‌پذیر است. (در این مرحله پیاده‌سازی کامل یک سیستم تولیدی مد نظر نیست)

---

## معماری کلی سیستم
سیستم به‌صورت یک پایپ‌لاین چندمرحله‌ای طراحی شده است:

1. **یافتن کانال‌ها (Discovery)**
2. **اعتبارسنجی کانال‌های فروشگاهی (Validation)**
3. **خزش و استخراج داده محصولات (Crawling & Extraction)**
4. **ارسال داده‌ها به صف (Queuing)**

داده‌های استخراج‌شده مستقیماً در پایگاه داده ذخیره نمی‌شوند و به‌عنوان Job در صف قرار می‌گیرند تا توسط سرویس‌های دیگر پردازش شوند.

---

## مراحل پایپ‌لاین

### 1. کشف کانال‌ها
در این مرحله، با استفاده از مجموعه‌ای از کلمات کلیدی مرتبط با فروش محصولات، کانال‌های کاندید از طریق قابلیت جستجوی Global ایتا استخراج می‌شوند.

> در نسخه MVP، کلمات کلیدی به‌صورت ثابت (hardcoded) تعریف شده‌اند و تولید داینامیک کلیدواژه ها با استفاده از مدل‌های زبانی (LLMs) به‌عنوان گامهای بعدی توسعه سیستم در نظر گرفته شده است.

---

### 2. اعتبارسنجی کانال‌ها
از آن‌جایی که بسیاری از کانال‌ها ممکن است از هشتگ‌های فروش استفاده کنند ولی فروشگاه نباشند، محتوای اولیه کانال (Bio و چند پست آخر) بررسی می‌شود تا فروشگاهی بودن کانال تشخیص داده شود.

این اعتبارسنجی می‌تواند به‌صورت:
- rule-based
- یا با استفاده از یک مدل زبانی ساده

انجام شود.
> از آنجایی که تمرکز اصلی این سرویس در مرحله MVP روی پالایش و آماده سازی اطلاعات پست های کانالهای فروشگاهی (برای پردازش های بعدی) است، اعتبارسنجی از طریق مدل زبانی فقط در صورت اجازه دادن ددلاین در این مرحله انجام خواهد شد. در غیر اینصورت به عنوان اولویت در مرحله بعدی توسعه محسوب خواهد شد.

---

### 3. پالایش و استخراج داده
برای کانال‌های تأییدشده:
- پیام‌ها پالایش یا خزش (crawl) می‌شوند
- پست‌های مرتبط با محصول از سایر پیام‌ها تفکیک می‌گردند
- اطلاعات محصول شامل متن کامل و لینک تصاویر استخراج می‌شود (extraction)

---

### 4. مدیریت صف (Redis)
هر محصول استخراج‌شده به‌صورت یک Job مستقل در صف Redis قرار می‌گیرد.
این طراحی باعث جداسازی فرآیند استخراج از پردازش‌های بعدی می‌شود و مقیاس‌پذیری سیستم را افزایش می‌دهد.

---

## کار با APIها
این پروژه شامل تعامل با چند API خارجی است:
- API پلتفرم ایتا (جستجو، دریافت پیام‌ها، فایل‌ها)
- API مدل‌های زبانی (در صورت استفاده)
- API Redis برای مدیریت صف

این کلاینت‌ها به‌گونه‌ای طراحی شده‌اند که مدیریت خطا، timeout، retry و محدودسازی ساده نرخ ارسال درخواست‌ها (در سطح هر درخواست) را پوشش دهند تا پایداری سیستم حفظ شود.

---

## مدیریت Rate Limit و Multi-Session
پلتفرم ایتا محدودیت‌هایی روی تعداد و سرعت درخواست‌های هر اکانت اعمال می‌کند. در نسخه MVP از یک session استفاده شده است، اما معماری سیستم به‌گونه‌ای طراحی شده که در مراحل بعدی امکان استفاده از چندین session و توزیع بار crawl بین آن‌ها وجود داشته باشد تا از بلاک شدن اکانت‌ها جلوگیری شود و مقیاس‌پذیری سیستم افزایش یابد.


---

## ملاحظات معماری و محدودیت‌های ایتا

پلتفرم ایتا محدودیت‌هایی روی نرخ درخواست‌ها (Rate Limit) و تعداد درخواست‌های هر session اعمال می‌کند.  
برای مدیریت این محدودیت‌ها، معماری سیستم به‌صورت pipeline و decoupled طراحی شده است.

### راهکارهای در نظر گرفته‌شده:
- جداسازی فرآیند crawl از پردازش‌های بعدی با استفاده از صف Redis
- طراحی SessionManager برای پشتیبانی از multi-session در آینده
- امکان توزیع بار crawl بین sessionها برای جلوگیری از بلاک شدن
- محدودسازی ساده نرخ درخواست‌ها (RateLimiter) در سطح سرویس

در نسخه MVP، فقط یک session فعال است، اما ساختار SessionManager و منطق multi-session به‌صورت کامل طراحی و پیاده‌سازی اولیه شده است تا در مراحل بعدی بدون تغییر معماری قابل توسعه باشد.

---
## تکنولوژی‌های استفاده‌شده
- Python
- Redis
- Docker & Docker Compose

---

## استفاده از هوش مصنوعی (AI)

در این پروژه، هوش مصنوعی به‌صورت هدفمند و محدود استفاده شده است تا معماری سیستم پیچیده نشود و تمرکز روی core pipeline باقی بماند.

### موارد استفاده از AI در MVP
- تولید کلمات کلیدی برای مرحله Discovery بر اساس دسته‌بندی محصول
- امکان استفاده از AI برای اعتبارسنجی کانال‌ها در مراحل بعدی توسعه

### مثال پرامپت تولید کلمات کلیدی
```text
Generate 10 Persian search keywords to find '<category>' shops on a messenger.
Focus on commercial intent like online buying, discounts, delivery, pricing.
Return ONLY the keywords separated by commas.
```
در نسخه MVP، پاسخ AI به‌صورت شبیه‌سازی‌شده پیاده‌سازی شده است و اتصال به مدل واقعی در فازهای بعدی بدون تغییر معماری امکان‌پذیر خواهد بود.

---

## محدودیت‌ها و تصمیمات طراحی
- در این نسخه از پایگاه داده استفاده نشده است. (فعلا نیازی نبوده است)
- تمرکز بر ارائه یک MVP پایدار و قابل توسعه بوده است.

---

## نحوه نصب و راه‌اندازی پروژه

### پیش‌نیازها
- Docker
- Docker Compose

### اجرای پروژه
ابتدا پروژه را clone کنید:

```bash
git clone git@github.com:MohammadJavid-Hosseini/eitaa-product-crawler.git
cd eitaa-product-crawler
```

سپس سرویس ها را اجرا کنید:
```bash
docker compose up --build
```

برای مشخص کردن دسته‌بندی محصولات (Category) می‌توان از آرگومان خط فرمان استفاده کرد: 
```bash
docker compose run crawler_app python src/main.py --category "پوشاک مردانه"
```
در صورت عدم ارسال آرگومان، مقدار پیش‌فرض «کالا و محصولات فروشی» استفاده خواهد شد.
